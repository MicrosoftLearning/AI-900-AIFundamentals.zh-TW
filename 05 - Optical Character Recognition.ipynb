{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 光學字元辨識\r\n",
        "\r\n",
        "![一個傀儡程式正在讀取報紙](./images/ocr.jpg)\r\n",
        "\r\n",
        "一般的電腦視覺挑戰是在影像中偵測和解譯文字。這種處理通常被稱為*光學字元辨識* (OCR)。\r\n",
        "\r\n",
        "## 使用電腦視覺服務讀取影像中的文字\r\n",
        "\r\n",
        "**電腦視覺**認知服務為 OCR 工作提供支援，包括：\r\n",
        "\r\n",
        "- 您可以使用 **OCR** API 來讀取包含多種語言的文字。此 API 可同步使用，且當您需要在影像中偵測和讀取少量文字時，其表現出色。\r\n",
        "- 較大文件的最佳**讀取** API。此 API 非同步使用，可用於列印和手寫這兩種文字。\r\n",
        "\r\n",
        "您可以透過建立**電腦視覺**資源或**認知服務**資源來使用此服務。\r\n",
        "\r\n",
        "若您還未這樣做，請在您的 Azure 訂用帳戶中建立**認知服務**資源。\r\n",
        "\r\n",
        "> **備註**：若您已經有認知服務資源，只需在 Azure 入口網站中開啟其 **[快速入門]** 頁面並將其金鑰和端點複製到下面的儲存格。否則，可追隨下面的步驟來建立一個認知服務資源。\r\n",
        "\r\n",
        "1. 在其它瀏覽器索引標籤中，透過 https://portal.azure.com 開啟 Azure 入口網站，並用您的 Microsoft 帳戶登入。\r\n",
        "\r\n",
        "2. 按一下 **[&#65291; 建立資源]** 按鈕，搜尋*認知服務*，並建立包含以下設定的**認知服務**資源：\r\n",
        "    - **訂用帳戶**： *您的 Azure 訂用帳戶*。\r\n",
        "    - **資源群組**： *選取或建立具有唯一名稱的資源群組*。\r\n",
        "    - **區域**： *選擇任一可用區域*：\r\n",
        "    - **名稱**： *輸入唯一名稱*。\r\n",
        "    - **定價層**：S0\r\n",
        "    - **我確認已閱讀通知並理解通知內容**：已選取。\r\n",
        "3. 等待部署完成。然後前往您的認知服務資源，在 **[概觀]** 頁面上，按一下連結以管理服務金鑰。您將需要端點和金鑰，以便從用戶端應用程式連線到您的認知服務資源。\r\n",
        "\r\n",
        "### 獲取您的認知服務資源之金鑰和端點\r\n",
        "\r\n",
        "若要使用您的認知服務資源，用戶端應用程式需要其端點和驗證金鑰：\r\n",
        "\r\n",
        "1. 在 Azure 入口網站中，您的認知服務資源之 **[金鑰和端點]** 頁面上，複製您的資源之**金鑰 1**並將其貼上到下面的程式碼，取代 **YOUR_COG_KEY**。\r\n",
        "2. 複製您的資源之**端點**並將其貼上到下面的程式碼，代替 **YOUR_COG_ENDPOINT**。\r\n",
        "3. 透過按一下 **[執行儲存格]** (&#9655;) 按鈕 (位於儲存格左側) 執行下方儲存格中的程式碼。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694246277
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "現在您已經設定好金鑰和端點，可以使用電腦視覺服務資源從影像中擷取文字。\r\n",
        "\r\n",
        "我們從 **OCR** API 開始，它使您能夠同步分析影像並讀取其包含的任一文字。在此案列中，您會得到虛構的 Northwind Traders 零售公司的廣告影像，其中包括一些文字。執行下方儲存格以讀取這些文字。 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Use the Computer Vision service to find text in the image\r\n",
        "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694257280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在影像中找到的文字被組織成由區域、行和詞組成的階層式結構，並且程式碼會讀取它們以取出結果。\r\n",
        "\r\n",
        "在結果中，檢視影像上方已讀取的文字。 \r\n",
        "\r\n",
        "## 顯示周框方塊\r\n",
        "\r\n",
        "結果還包括文字行的*周框方塊*座標和在影像中找到的單個詞。執行下方儲存格以查看您從上方取出的廣告影像中文字行的周框方塊。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Show the position of the line of text\n",
        "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
        "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Show the image with the text locations highlighted\r\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694266106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在結果中，每個文字行的周框方塊都呈矩形顯示在影像上。\r\n",
        "\r\n",
        "## 使用讀取 API\r\n",
        "\r\n",
        "您之前使用的 OCR API 在處理帶有少量文字的影像時表現良好。當您需要讀取大量文字時，例如掃描的文件，您可以使用**讀取** API。這需要多個步驟處理：\r\n",
        "\r\n",
        "1. 將影像提交至電腦視覺服務以便非同步地讀取和分析影像。\r\n",
        "2. 等待分析作業完成。\r\n",
        "3. 取出分析結果。\r\n",
        "\r\n",
        "執行以下儲存格以使用此處理來讀取給 Northwind Traders 商店管理員的掃描信件中的文字。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694312346
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "檢閱結果。此處有完整的信件轉譯，其主要由帶有手寫簽章的印列文字組成。信件的原始影像顯示在 OCR 結果下方 (您可能需要捲動以便參閱該影像)。\r\n",
        "\r\n",
        "## 讀取手寫文字\r\n",
        "\r\n",
        "在上一個範例中，分析影像的要求指定了一種文字辨識模式，此模式使文字*列印*作業最佳化。注意，儘管如此，還是讀取了手寫簽章。\r\n",
        "\r\n",
        "這種讀取手寫文字的能力用處極大。例如，假設您已寫下一條包含購物清單的備註，並想使用您手機上的一款應用程式來讀取此備註並轉譯其包含的文字。\r\n",
        "\r\n",
        "執行下方儲存格以參閱手寫購物清單讀取作業的範例。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'note.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694340593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 更多資訊\r\n",
        "\r\n",
        "有關使用適用於 OCR 的電腦視覺服務之更多資訊，請參閱[電腦視覺文件](https://docs.microsoft.com/zh-tw/azure/cognitive-services/computer-vision/concept-recognizing-text)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}