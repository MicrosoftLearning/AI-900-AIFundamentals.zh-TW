{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 偵測和分析臉部\n",
    "\n",
    "電腦視覺解決方案通常需要人工智慧 (AI) 解決方案，以便能夠偵測、分析或識別人類臉部。例如，假設零售公司 Northwind Traders 已經決定實作「智慧商店」，在智慧商店中 AI 服務監視商店，以便識別需要幫助的客戶，並指揮員工去幫助他們。實現此目標的一種方式是執行臉部偵測和分析，換言之，即判斷影像中是否出現任何臉部，若有，則分析其特徵。\n",
    "\n",
    "![一個傀儡程式正在分析臉部](./images/face_analysis.jpg)\n",
    "\n",
    "## 使用臉部認知服務來偵測臉部\n",
    "\n",
    "假設 Northwind Traders 想要建立的智慧商店系統需要能夠偵測客戶並分析其臉部特徵。在 Microsoft Azure 中，您可以使用**臉部** (Azure 認知服務的組成部分) 來達成此目標。\n",
    "\n",
    "### 建立認知服務資源\n",
    "\n",
    "讓我們首先在您的 Azure 訂用帳戶中建立**認知服務**資源。\n",
    "\n",
    "> **備註**：若您已經有認知服務資源，只需在 Azure 入口網站中開啟其 [**快速入門**] 頁面並將其金鑰和端點複製到下面的儲存格。否則，可追隨下面的步驟來建立一個認知服務資源。\n",
    "\n",
    "1. 在其它瀏覽器索引標籤中，透過 https://portal.azure.com 開啟 Azure 入口網站，用您的 Microsoft 帳戶登入。\n",
    "2. 按一下 [**&#65291; 建立資源**] 按鈕，搜尋*認知服務*， 並建立包含以下設定的**認知服務**資源：\n",
    "    - **訂用帳戶**：*您的 Azure 訂用帳戶*。\n",
    "    - **資源群組**：*選取或建立具有唯一名稱的資源群組*。\n",
    "    - **區域**：*選擇任一可用區域*：\n",
    "    - **名稱**：*輸入唯一名稱*。\n",
    "    - **定價層**：S0\n",
    "    - **我確認已閱讀通知並理解通知內容**：已選取。\n",
    "3. 等待部署完成。然後前往您的認知服務資源，在 [**概觀**] 頁面上，按一下連結以管理服務金鑰。您將需要端點和金鑰，以便從用戶端應用程式連線到您的認知服務資源。\n",
    "\n",
    "### 獲取您的認知服務資源之金鑰和端點\n",
    "\n",
    "若要使用您的認知服務資源，用戶端應用程式需要其端點和驗證金鑰：\n",
    "\n",
    "1. 在 Azure 入口網站中，您的認知服務資源之 [**金鑰和端點**] 頁面上，複製您的資源之**金鑰 1** 並將其貼上到下面的程式碼，取代 **YOUR_COG_KEY**。\n",
    "\n",
    "2. 複製您的資源之**端點**並將其貼上到下面的程式碼，代替 **YOUR_COG_ENDPOINT**。\n",
    "\n",
    "3. 透過按一下 [執行儲存格] <span>&#9655;</span> 按鈕 (位於儲存格左上方) 執行下面的儲存格中的程式碼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在您擁有認知服務資源，可以使用臉部服務來偵測商店中的人類臉部。\n",
    "\n",
    "執行下面的程式碼儲存格以便查看範例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "唯一的識別碼已指派給每張已偵測到的臉部，因此您的應用程式可以識別已偵測到的每一張個人臉部身分。\n",
    "\n",
    "執行下面的儲存格以便查看更多顧客臉部的識別碼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析臉部屬性\n",
    "\n",
    "臉部不只是能簡單地偵測臉部，還有更多功能。臉部亦可分析臉部特徵和表情來提示年齡和情緒狀態；例如，執行下面的程式碼來分析顧客的臉部屬性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據影像中為客戶偵測到的情緒分數，客戶似乎對購物體驗頗為滿意。\n",
    "\n",
    "## 尋找相似的臉部 \n",
    "\n",
    "臉部識別碼 (為每張已偵測到的臉部而建立) 用於單獨識別臉部偵測。您可以使用這些識別碼將已偵測到的臉部與之前已偵測到的臉部進行比較，並尋找具有相似特徵的臉部。\n",
    "\n",
    "例如，執行下面的儲存格來比較一張影像和另一張影像中的顧客，並尋找相符的臉部。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 識別臉部\n",
    "\n",
    "到目前為止，您已經看到臉部可以偵測臉部和臉部特徵，還可以識別彼此相似的兩張臉部身分。您可以透過實作臉部識別解決方案更進一步，在該解決方案中訓練臉部以便識別特定的人臉。該解決方案在各種案例中均實用，例如在社交媒體應用程式中自動標記朋友的相片，或使用臉部識別作為生物特徵身分識別驗證系統的一部分。\n",
    "\n",
    "為了了解其工作原理，我們假設 Northwind Traders 公司想要使用臉部識別來確保只有 IT 部門中獲得授權的員工可以存取安全系統。\n",
    "\n",
    "我們首先建立一個*人員群組*來代表獲得授權的員工。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在已有*人員群組*，我們可以為想要納入群組的每位員工新增一個*人員*，然後註冊每個人的多張相片以便臉部可以了解每個人的相異臉部特性。理想情況下，影像應該顯示同一個人，這個人呈現不同造型和不同的臉部表情。\n",
    "\n",
    "我們將新增一位名叫 Wendell 的員工，並註冊這名員工的三張相片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Add a person (Wendell) to the group\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Get photo's of Wendell\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# Register the photos\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # Add each photo to person in person group\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # Display each image\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過已新增的人員和已註冊的相片，我們現在可以訓練臉部來識別每個人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在，透過已訓練的模型，您可以用它來識別影像中已識別的臉部身分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# Get the face IDs in a second image\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# Get recognized face names\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# show recognized faces\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深入瞭解\n",
    "\n",
    "若要深入了解臉部認知服務，請查看[臉部文件](https://docs.microsoft.com/azure/cognitive-services/face/)\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}