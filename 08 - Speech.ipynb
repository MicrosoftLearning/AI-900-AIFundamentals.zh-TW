{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 語音\r\n",
        "\r\n",
        "我們愈發期望能夠透過與 AI 對話來與人工智慧 (AI) 系統交談，我們通常懷著對語音回應的期待。\r\n",
        "\r\n",
        "![一個傀儡程式在說話](./images/speech.jpg)\r\n",
        "\r\n",
        "*語音辨識* (解譯語音語言的 AI 系統) 和*語音合成* (生成語音回應的 AI 系統) 是啟用語音的 AI 解決方案的關鍵元件。\r\n",
        "\r\n",
        "## 建立認知服務資源\r\n",
        "\r\n",
        "若要組建可以解譯聲音語音和口頭回應的軟體，您可以使用**語音**認知服務，它提供一種直接將語音語言轉譯為文字的方法 (反之亦然)。\r\n",
        "\r\n",
        "如果您還沒有該資源，請使用以下步驟在您的 Azure 訂用帳戶中建立一個**認知服務**資源：\r\n",
        "\r\n",
        "> **備註**：若您已經有認知服務資源，只需在 Azure 入口網站中開啟其 **[快速入門]** 頁面並將其金鑰和端點複製到下面的儲存格。否則，可追隨下面的步驟來建立一個認知服務資源。\r\n",
        "\r\n",
        "1. 在其它瀏覽器索引標籤中，透過 https://portal.azure.com 開啟 Azure 入口網站，並用您的 Microsoft 帳戶登入。\r\n",
        "2. 按一下 **[&#65291; 建立資源]** 按鈕，搜尋*認知服務*，並建立包含以下設定的**認知服務**資源：\r\n",
        "    - **訂用帳戶**： *您的 Azure 訂用帳戶*。\r\n",
        "    - **資源群組**： *選取或建立具有唯一名稱的資源群組*。\r\n",
        "    - **區域**： *選擇任一可用區域*：\r\n",
        "    - **名稱**： *輸入唯一名稱*。\r\n",
        "    - **定價層**：S0\r\n",
        "    - **我確認已閱讀通知並理解通知內容**：已選取。\r\n",
        "3. 等待部署完成。然後前往您的認知服務資源，在 **[概觀]** 頁面上，按一下連結以管理服務金鑰。您將需要金鑰和位置以便從用戶端應用程式連線到您的認知服務資源。\r\n",
        "\r\n",
        "### 獲取適用於認知服務資源的金鑰和位置\r\n",
        "\r\n",
        "若要使用您的認知服務資源，用戶端應用程式需要其驗證金鑰和位置：\r\n",
        "\r\n",
        "1. 在 Azure 入口網站中，您的認知服務資源之 **[金鑰和端點]** 頁面上，複製您的資源之**金鑰 1** 並將其貼上到下面的程式碼，取代 **YOUR_COG_KEY**。\r\n",
        "2. 複製您的資源之**位置**並將其貼上到下面的程式碼中，取代 **YOUR_COG_LOCATION**。\r\n",
        ">**備註**：留在 **[金鑰和端點]** 頁面並從此頁面複製**位置**(範例：_westus_)。請 _勿_ 在 [位置] 欄位的文字之間增加空格。 \r\n",
        "3. 透過按一下儲存格左側的 **[執行儲存格]** (&#9655;) 按鈕執行下方程式碼。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      },
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 語音辨識\r\n",
        "\r\n",
        "假設您想要組建接受語音指示 (例如「開燈」或「關燈」) 的首頁自動化系統。您的應用程式需要能夠接受以音訊為基礎的輸入 (您的語音指示)，並透過將其轉譯成可以剖析和分析的文字來解譯它。\r\n",
        "\r\n",
        "現在您可以準備轉譯若干語音。輸入可以來自**麥克風**或**音訊檔案**。 \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 語音辨識和音訊檔案\r\n",
        "\r\n",
        "執行下方儲存格來查看使用**音訊檔案**的語音辨識服務。 \r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Get spoken command from audio file\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Configure speech recognizer\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Use a one-time, synchronous call to transcribe the speech\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Play the original audio file\r\n",
        "playsound(audio_file)\n",
        "\n",
        "# Show transcribed text from audio file\r\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 語音合成\r\n",
        "\r\n",
        "那麼現在您已經看過語音服務是怎樣把語音轉譯為文字的，但是反過來又是怎樣的呢？您該怎樣把文字轉換成語音呢？\r\n",
        "\r\n",
        "那麼，讓我們假設您的首頁自動化系統已經解譯了開燈命令。適用的回應也許可以確認口頭命令 (以及實際執行命令的任務！)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Get text to be spoken\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Configure speech synthesis\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Transcribe text into speech\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Display an appropriate image  \r\n",
        "file_name = response_text.lower() + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "嘗試將 **response_text** 變數變更為 *Turning the light off.* (包括末尾的句點) 並再次執行儲存格以聆聽結果。\r\n",
        "\r\n",
        "## 了解更多資訊\r\n",
        "\r\n",
        "在此 Notebook 中您已看過非常簡單的使用語音認知服務的範例。您可以在語音服務文件中了解更多關於[語音轉換文字](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text)和[文字轉換語音](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech)。"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}