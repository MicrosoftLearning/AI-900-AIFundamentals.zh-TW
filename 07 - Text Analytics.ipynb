{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 文字分析\r\n",
        "\r\n",
        "自然語言處理 (NLP) 是處理書面和口語語言之人工智慧 (AI) 的分支。您可以使用 NLP 來組建從文字或語音中擷取語意的解決方案，或在自然語言中制訂有意義之回應的解決方案。\r\n",
        "\r\n",
        "Microsoft Azure *認知服務*包含*文字分析*服務，該服務提供立即可用的 NLP 功能，包括識別文字中的關鍵片語以及根據情緒分類文字。\r\n",
        "\r\n",
        "![一個傀儡程式正在讀取 Notebook](./images/NLP.jpg)\r\n",
        "\r\n",
        "例如，假設虛構組織 *Margie's Travel*鼓勵客戶提交關於旅館住宿的評論。您可以使用文字分析服務透過擷取關鍵片語的方式來摘要評論，判斷哪些評論是好評，哪些是差評，或分析提及已知實體 (例如位置或人) 的評論文字。\r\n",
        "\r\n",
        "## 檢視評論文件\r\n",
        "\r\n",
        "我們首先來看一看客戶給旅館留下的一些評論。\r\n",
        "\r\n",
        "評論在文字檔中。若要查看評論，只需透過按一下儲存格左側的 **[執行儲存格]** (&#9655;) 按鈕來執行下面的程式碼。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立認知服務資源\r\n",
        "\r\n",
        "若要分析這些評論中的文字，您可以使用**文字分析**認知服務。若要使用這些評論，您需要在您的 Azure 訂用帳戶中建置一個**文字分析**或**認知服務**資源 (如果這是您計劃使用或您想要另行追蹤其使用方式的唯一服務，請使用文字分析資源；否則，您可以使用認知服務資源將文字分析服務和其它認知服務組合，確保開發人員使用單一端點和金鑰來存取它們。)\r\n",
        "\r\n",
        "如果您還沒有該資源，請使用以下步驟在您的 Azure 訂用帳戶中建立一個**認知服務**資源：\r\n",
        "\r\n",
        "> **備註**：若您已經有認知服務資源，只需在 Azure 入口網站中開啟其 **[快速入門]** 頁面並將其金鑰和端點複製到下面的儲存格。否則，可追隨下面的步驟來建立一個認知服務資源。\r\n",
        "\r\n",
        "1. 在其它瀏覽器索引標籤中，透過 https://portal.azure.com 開啟 Azure 入口網站，並用您的 Microsoft 帳戶登入。\r\n",
        "2. 按一下 **[&#65291; 建立資源]** 按鈕，*搜尋認知服務*，並建立包含以下設定的**認知服務**資源：\r\n",
        "    - **訂用帳戶**： *您的 Azure 訂用帳戶*。\r\n",
        "    - **資源群組**： *選取或建立具有唯一名稱的資源群組*。\r\n",
        "    - **區域**： *選擇任一可用區域*：\r\n",
        "    - **名稱**： *輸入唯一名稱*。\r\n",
        "    - **定價層**：S0\r\n",
        "    - **我確認已閱讀通知並理解通知內容**：已選取。\r\n",
        "3. 等待部署完成。然後前往您的認知服務資源，在 **[概觀]** 頁面上，按一下連結以管理服務金鑰。您將需要端點和金鑰，以便從用戶端應用程式連線到您的認知服務資源。\r\n",
        "\r\n",
        "### 獲取您的認知服務資源之金鑰和端點\r\n",
        "\r\n",
        "若要使用您的認知服務資源，用戶端應用程式需要其端點和驗證金鑰：\r\n",
        "\r\n",
        "1. 在 Azure 入口網站中，您的認知服務資源之 **[金鑰和端點]** 頁面上，複製您的資源之**金鑰 1** 並將其貼上到下面的程式碼，取代 **YOUR_COG_KEY**。\r\n",
        "2. 複製您的資源之**端點**並將其貼上到下面的程式碼，代替 **YOUR_COG_ENDPOINT**。\r\n",
        "3. 透過按一下其綠色 <span style=\"color:green\">&#9655;</span> 按鈕執行下面的儲存格中的程式碼。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 偵測語言\r\n",
        "我們首先識別書寫評論所使用的語言。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 擷取關鍵片語\r\n",
        "\r\n",
        "現在您可以分析客戶評論中的文字以識別可以指示主要論題的關鍵片語。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "關鍵片語可以幫助您理解每條評論中最重要的論題。例如，包含片語「員工樂於助人」或「服務差」的評論可以給您指示評論者的一些主要關注點。\r\n",
        "\r\n",
        "## 判斷情緒\r\n",
        "\r\n",
        "根據情緒*分數*將評論分類為*好評*或*差評*可能會有用。此外，您可以使用文字分析服務來實現這一目標。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 擷取已知實體\r\n",
        "\r\n",
        "*實體*是可能會在文字中提及的事物，涉及一些常見的項目類型。例如，位置、人或日期。我們假設您對評論中提及的日期和地點感興趣，您可以使用以下程式碼找到它們。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "請注意，某些較為知名的實體擁有相關聯的維基百科頁面，在這種情況下，文字分析服務會退回該頁面的 URL。\r\n",
        "\r\n",
        "## 瞭解更多資訊\r\n",
        "\r\n",
        "有關文字分析服務的更多資訊，請查看[文字分析服務文件](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}